---
title: "vedmi"
output: html_document
date: "2024-01-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(rvest)
library(tidyverse)
```
```{r}

url <- "https://chernayamagiya.com/forum/index.php/topic,9923.0.html" 

page <- read_html(url)

class(page)#demonstrates for you the class of the object in R
```

```{r}
# ".js-item-name" - is the name of the product that I got using selector gadget.

names_com<-page %>%
  html_nodes(".col-md-2 a") %>% #Specifies location of text to be scraped
  html_text(trim = TRUE) #Returns data as text
```

```{r}
page %>%
  html_nodes(".inner") %>% #Specifies location of text to be scraped
  html_text(trim = TRUE) #Returns data as text
```

```{r}
page %>%
  html_nodes(".keyinfo .smalltext") %>% #Specifies location of text to be scraped
  html_text(trim = TRUE)#Returns data as text
```
```{r}
urls <- sprintf("https://chernayamagiya.com/forum/index.php/topic,9923.%d.html", 1:202) #saving the list with urls for crawler

urls
```

```{r}
Allnames <- data.frame() #Creates an empty dataframe to store data

for (i in urls){
  page <- read_html(i)
  
  Names <- page %>%
    html_nodes(".col-md-2 a") %>%
    html_text(trim = TRUE)
  
  temp <- as.data.frame(Names)
  Allnames <- rbind(Allnames, temp)
  Sys.sleep(1)#is used to avoid blockage from sites, 
  #makes 5 sec break between download from each page
}
```




```{r}
Alltext <- data.frame() #Creates an empty dataframe to store data

for (i in urls){
  page <- read_html(i)
  
  Texts <- page %>%
    html_nodes(".inner") %>%
    html_text(trim = TRUE)
  
  temp <- as.data.frame(Texts)
  Alltext <- rbind(Alltext, temp)
  Sys.sleep(1)#is used to avoid blockage from sites, 
  #makes 5 sec break between download from each page
}
```

```{r}
Alldate <- data.frame() #Creates an empty dataframe to store data

for (i in urls){
  page <- read_html(i)
  
  Dates <- page %>%
    html_nodes(".keyinfo .smalltext") %>%
    html_text(trim = TRUE)
  
  temp <- as.data.frame(Dates)
  Alldate <- rbind(Alldate, temp)
  Sys.sleep(1)
}
```

```{r}
scraped <- data.frame(
  Names=Allnames$Names,
  Texts = Alltext$Texts,
  Dates = Alldate$Dates
)
```

```{r}
write.csv(scraped,#the dataframe name
          "scraped.csv",# your file name
          row.names = TRUE)# you indicate that you want to save the rownames
```



5.02.2024
```{r}
library("quanteda")
```
```{r}
corp_magic <- corpus(as.character(скреи_пинг_upd$Texts))
```

```{r}
summary(corp_magic)
```
```{r}
#не работает, тк у нас дата в неправильном формате.
docvars(corp_magic, "Publication_date") <- as.Date(скреи_пинг_upd$Dates2)
```

```{r}
data_tokens_magic <- tokens(corp_magic)
death_data<-kwic(data_tokens_magic, pattern = "смерт", valuetype = "regex", window = 30)
```

```{r}
corp_magic_1<-tokens(corp_magic, remove_numbers = TRUE, remove_punct = TRUE)
toks <- tokens(corp_magic_1)
toks_nostop <- tokens_select(toks, pattern = stopwords("ru"),
                             selection = "remove")
```

```{r}
#а эта работает!
stop2 <- c(stopwords("ru"), "+", "=", "Т", "е")
corp_magic_1<-tokens(corp_magic, remove_numbers = TRUE, remove_punct = TRUE)
toks <- tokens(corp_magic_1)
toks_nostop <- tokens_select(toks, pattern = stop2,
                             selection = "remove")
```


```{r}
#эта строчка работает неправильно! 
#нужно переписать, чтобы использовать. См. лабу номер 2.
toks_nostop <- tokens_select(toks, pattern = c("=", "это", "иже", "и", "но", "да", "с", "а", "в", "т", "е", "как", "или", "на", "то", "не", "по", "что", "я", "все", "у", "если", "раз", "ли", "можно", "кто", "за", "+", "=", "так", "мне", "к", "мне", "они", "его", "ее", "оно", "она", "он", "быть", "как", "той", "тот", "этот", "это", "от", "нет", "может", "будет", "бы", "есть", "вы", "еще", "уже", "надо", "еще", "один", "же", "тоже", "там", "сей", "лучше", "один", "для", "только", "очень", "их", "после"),
                                   padding = TRUE,  selection = "remove")
```


```{r}
dfm_magic <- dfm(toks_nostop)
```

```{r}
topfeatures(dfm_magic, 40)
```
```{r}
set.seed(100)# settng seed is important for the functions
#that could provide different results because of iterations
library("quanteda.textplots")
textplot_wordcloud(dfm_magic, min_count = 100,
                   random_order = FALSE, 
                   rotation = 0.25,
    color = RColorBrewer::brewer.pal(8, "Dark2"))
```

```{r}
kwic(tokens(corp_magic_1), pattern = "свечи") %>% textplot_xray()
```

```{r}
library("quanteda.textplots")
abrakadabra <- fcm(dfm_magic) 
```

```{r}
feat <- names(topfeatures(abrakadabra, 50))
set.seed(100)
fcm_select(abrakadabra, pattern = feat) %>%
    textplot_network(min_freq = 0.5,edge_color = "gold",
                 edge_alpha = 0.8,
                 edge_size = 1,
                 vertex_color = "grey",
                 vertex_alpha = 0.5,
                 vertex_labelcolor = "black",
                 offset = NULL)
```

```{r}
library("quanteda.textstats")
library("ggplot2")

# Предположим, что у вас есть текстовые данные, которые вы хотите анализировать, и они хранятся в переменной abrakadabra
# Создайте объект типа dfm из текста
abrakadabra_dfm <- dfm(abrakadabra)

# Получите частоту встречаемости токенов (слов) в тексте
features_dfm_magic <- textstat_frequency(abrakadabra_dfm, n = 30)

# Сортируем по убыванию частоты
features_dfm_magic$feature <- with(features_dfm_magic, reorder(feature, -frequency))

# Создаем график
ggplot(features_dfm_magic, aes(x = feature, y = frequency)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

